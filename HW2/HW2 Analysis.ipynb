{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# File managing imports\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import json\n",
    "\n",
    "# np and torch stuff\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "# Imports specific to doc2vec and NLP\n",
    "import gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import nltk\n",
    "\n",
    "#sys.path.append(os.getcwd() + '/..')\n",
    "\n",
    "# To read the files and qrels\n",
    "import read_ap\n",
    "import download_ap\n",
    "\n",
    "# Model and helper imports\n",
    "from model import SkipGramNet\n",
    "from helper import build_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"More than 150 former officers of the\n",
    "overthrown South Vietnamese government have been released from a\n",
    "re-education camp after 13 years of detention, the official Vietnam\n",
    "News Agency reported Saturday.\n",
    "The report from Hanoi, monitored in Bangkok, did not give\n",
    "specific figures, but said those freed Friday included an\n",
    "ex-Cabinet minister, a deputy minister, 10 generals, 115\n",
    "field-grade officers and 25 chaplains.\n",
    "   It quoted Col. Luu Van Ham, director of the Nam Ha camp south of\n",
    "Hanoi, as saying all 700 former South Vietnamese officials who had\n",
    "been held at the camp now have been released.\n",
    "   They were among 1,014 South Vietnamese who were to be released\n",
    "from re-education camps under an amnesty announced by the Communist\n",
    "government to mark Tet, the lunar new year that begins Feb. 17.\n",
    "   The Vietnam News Agency report said many foreign journalists and\n",
    "a delegation from the Australia-Vietnam Friendship Association\n",
    "attended the Nam Ha release ceremony.\n",
    "   It said Lt. Gen. Nguyen Vinh Nghi, former commander of South\n",
    "Vietnam's Third Army Corps, and Col. Tran Duc Minh, former director\n",
    "of the Army Infantry Officers School, expressed ``gratitude to the\n",
    "government for its humane treatment in spite of the fact that most\n",
    "of them (detainees) had committed heinous crimes against the\n",
    "country and people.''\n",
    "   The prisoners had been held without formal charges or trial\n",
    "since North Vietnam defeated the U.S.-backed South Vietnamese\n",
    "government in April 1975, ending the Vietnam War.\n",
    "   Communist authorities had called the prisoners war criminals and\n",
    "said they had to learn how to become citizens of the new society.\n",
    "   Small numbers had been released occasionally without publicity\n",
    "but the government announced last year that 480 political prisoners\n",
    "would be freed to mark National Day on Sept. 2.\n",
    "   On Thursday, Vice Minister of Information Phan Quang said 1,014\n",
    "would be released under the Tet amnesty.\n",
    "   He reported a total of 150 prisoners would remain in the camps,\n",
    "which he said once held 100,000.\n",
    "   ``Depending on their repentance, they will gradually be released\n",
    "within a short period of time,'' Quang said.\n",
    "   He said many of the former inmates would return to their\n",
    "families in Ho Chi Minh City, formerly the South Vietnamese capital\n",
    "of Saigon.\n",
    "   The amnesties apparently are part of efforts by Communist Party\n",
    "chief Nguyen Van Linh to heal internal divisions and improve\n",
    "Vietnam's image abroad.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"The president of the United States threatened with sanctions against Iran\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2vmodel = gensim.models.doc2vec.Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_ap.process_text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = d2vmodel.infer_vector(test_data)\n",
    "#print(\"V1 infer: \", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.docvecs.most_similar([v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(query, model, num_results = 10):\n",
    "    query = read_ap.process_text(query)\n",
    "    vec = model.infer_vector(query)\n",
    "    \n",
    "    return model.docvecs.most_similar([vec], topn = num_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ranks = ranking(query, model = d2vmodel, num_results = 164557)\n",
    "ranks = ranking(query, model = d2vmodel, num_results = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AP890807-0056', 0.7527885437011719),\n",
       " ('AP880720-0091', 0.7495495676994324),\n",
       " ('AP890904-0085', 0.7414106726646423),\n",
       " ('AP880728-0091', 0.7402305006980896),\n",
       " ('AP891211-0071', 0.7330125570297241),\n",
       " ('AP890618-0047', 0.7291489243507385),\n",
       " ('AP880731-0005', 0.724372923374176),\n",
       " ('AP890117-0091', 0.7233673334121704),\n",
       " ('AP880228-0003', 0.7211905121803284),\n",
       " ('AP880418-0049', 0.7195896506309509)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing index to specific document\n",
    "i2str = {}\n",
    "\n",
    "for i, doc in enumerate(docs_by_id):\n",
    "    i2str[i] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train New Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs already processed. Loading from disk\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the dataset\n",
    "download_ap.download_dataset()\n",
    "\n",
    "# pre-process the text\n",
    "docs_by_id = read_ap.get_processed_docs()\n",
    "# Instead of preprocessing maybe just do lemmatizing?\n",
    "\n",
    "# get qrels\n",
    "qrels, queries = read_ap.read_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(docs_by_id, tokens_only=False):\n",
    "    \n",
    "    for key, doc in docs_by_id.items():\n",
    "        if tokens_only:\n",
    "            yield doc\n",
    "        else:\n",
    "            # If data is used for training we require tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(doc, [key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(docs_by_id))\n",
    "test_corpus  = list(read_corpus(docs_by_id, tokens_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=250, epochs=15, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"d2v_200_10_5-2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs already processed. Loading from disk\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the dataset\n",
    "download_ap.download_dataset()\n",
    "\n",
    "# pre-process the text\n",
    "docs_by_id = read_ap.get_processed_docs()\n",
    "# Instead of preprocessing maybe just do lemmatizing?\n",
    "\n",
    "# get qrels\n",
    "qrels, queries = read_ap.read_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "docs = [doc for key, doc in docs_by_id.items()]\n",
    "\n",
    "# bigram = Phrases(docs, min_count=20)\n",
    "\n",
    "# for key, doc in docs_by_id.items():\n",
    "#     for token in bigram[docs_by_id[key]]:\n",
    "#         if '_' in token:\n",
    "#             # Token is a bigram, add to document.\n",
    "#             docs_by_id[key].append(token)\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bigram dictionary\n",
    "jsondocs = json.dumps(docs)\n",
    "f = open(\"bigram.json\",\"w\")\n",
    "f.write(jsondocs)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"bigram.json\"):\n",
    "    docs = json.load(open(\"bigram.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model import\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 1\n",
    "iterations = 1\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "word2id = dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"lda.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "model = LdaModel.load(\"lda.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.5004.\n",
      "[([(0.023758994, 'bush'),\n",
      "   (0.015403773, 'hous'),\n",
      "   (0.015127242, 'presid'),\n",
      "   (0.008998448, 'senat'),\n",
      "   (0.008307407, 'democrat'),\n",
      "   (0.007755701, 'vote'),\n",
      "   (0.0066285995, 'congress'),\n",
      "   (0.0065940414, \"n't\"),\n",
      "   (0.0064757434, 'state'),\n",
      "   (0.0063961814, 'committe'),\n",
      "   (0.0060074544, 'administr'),\n",
      "   (0.005851559, 'white'),\n",
      "   (0.0054646637, 'bill'),\n",
      "   (0.005427055, 'republican'),\n",
      "   (0.0048162234, 'white_hous'),\n",
      "   (0.0047033317, 'nation'),\n",
      "   (0.004427831, 'elect'),\n",
      "   (0.004368095, 'go'),\n",
      "   (0.0043071145, 'support'),\n",
      "   (0.004256229, 'campaign')],\n",
      "  -1.2514183593588153),\n",
      " ([(0.014035112, 'million'),\n",
      "   (0.01178711, 'compani'),\n",
      "   (0.007436369, 'billion'),\n",
      "   (0.006537955, 'percent'),\n",
      "   (0.006073426, 'new'),\n",
      "   (0.0045764567, 'program'),\n",
      "   (0.0044825953, 'plan'),\n",
      "   (0.0041710585, 'feder'),\n",
      "   (0.0041421424, 'state'),\n",
      "   (0.0040388815, 'industri'),\n",
      "   (0.0037687365, 'busi'),\n",
      "   (0.0036146569, 'also'),\n",
      "   (0.0035998167, 'use'),\n",
      "   (0.0035188734, 'oper'),\n",
      "   (0.0035111327, 'sale'),\n",
      "   (0.0034175387, 'product'),\n",
      "   (0.0033606936, 'includ'),\n",
      "   (0.003334762, 'servic'),\n",
      "   (0.0033246188, 'nation'),\n",
      "   (0.0032182764, 'corp.')],\n",
      "  -1.2916850974738416),\n",
      " ([(0.032129142, 'percent'),\n",
      "   (0.017451638, 'cent'),\n",
      "   (0.016867107, 'price'),\n",
      "   (0.012355181, 'rate'),\n",
      "   (0.008941601, 'trade'),\n",
      "   (0.00835369, 'higher'),\n",
      "   (0.008265268, 'lower'),\n",
      "   (0.0080893105, 'market'),\n",
      "   (0.008001401, 'dollar'),\n",
      "   (0.007502065, 'futur'),\n",
      "   (0.006361935, 'report'),\n",
      "   (0.006029754, 'new'),\n",
      "   (0.0057291603, 'rose'),\n",
      "   (0.005620989, 'increas'),\n",
      "   (0.0054833144, 'u.s.'),\n",
      "   (0.00546258, 'oil'),\n",
      "   (0.0053791506, 'pound'),\n",
      "   (0.0052910508, 'last'),\n",
      "   (0.0052803764, 'month'),\n",
      "   (0.0051418585, 'late')],\n",
      "  -1.2985735763633353),\n",
      " ([(0.008855602, \"n't\"),\n",
      "   (0.0058134818, 'new'),\n",
      "   (0.0053259446, 'one'),\n",
      "   (0.0043433374, 'peopl'),\n",
      "   (0.0043296623, 'say'),\n",
      "   (0.004244317, 'like'),\n",
      "   (0.003996966, 'time'),\n",
      "   (0.0039210543, 'school'),\n",
      "   (0.0035226005, 'show'),\n",
      "   (0.0035152955, 'work'),\n",
      "   (0.0034805872, 'first'),\n",
      "   (0.0034744623, 'get'),\n",
      "   (0.0032466433, 'go'),\n",
      "   (0.002789345, 'day'),\n",
      "   (0.0026031083, 'children'),\n",
      "   (0.0026003476, 'univers'),\n",
      "   (0.0025257738, 'home'),\n",
      "   (0.0024192983, 'live'),\n",
      "   (0.0024178075, 'famili'),\n",
      "   (0.0023572643, \"'re\")],\n",
      "  -1.350254925905281),\n",
      " ([(0.013271818, 'court'),\n",
      "   (0.009955422, 'drug'),\n",
      "   (0.009023594, 'case'),\n",
      "   (0.008578192, 'charg'),\n",
      "   (0.0069342135, 'judg'),\n",
      "   (0.006868763, 'state'),\n",
      "   (0.006427269, 'attorney'),\n",
      "   (0.006398599, 'investig'),\n",
      "   (0.005824656, 'law'),\n",
      "   (0.0054808655, 'feder'),\n",
      "   (0.00524559, 'offic'),\n",
      "   (0.004858555, 'u.s.'),\n",
      "   (0.0048329597, 'trial'),\n",
      "   (0.004608931, 'rule'),\n",
      "   (0.0045094076, 'prison'),\n",
      "   (0.004006756, 'convict'),\n",
      "   (0.0039774715, 'sentenc'),\n",
      "   (0.0038409983, 'two'),\n",
      "   (0.0037737528, 'former'),\n",
      "   (0.00376144, 'depart')],\n",
      "  -1.3850062791295266),\n",
      " ([(0.023862438, 'soviet'),\n",
      "   (0.013555633, 'east'),\n",
      "   (0.01006445, 'west'),\n",
      "   (0.010056125, 'german'),\n",
      "   (0.009718756, 'germani'),\n",
      "   (0.008704312, 'state'),\n",
      "   (0.0076673185, 'gorbachev'),\n",
      "   (0.006999491, 'offici'),\n",
      "   (0.006872175, 'europ'),\n",
      "   (0.0066640633, 'soviet_union'),\n",
      "   (0.0066332766, 'union'),\n",
      "   (0.006512729, 'u.s.'),\n",
      "   (0.0063861483, 'countri'),\n",
      "   (0.006173937, 'unit_state'),\n",
      "   (0.0061698016, 'unit'),\n",
      "   (0.004802387, 'communist'),\n",
      "   (0.004642172, 'east_german'),\n",
      "   (0.0046205902, 'world'),\n",
      "   (0.004462399, 'meet'),\n",
      "   (0.004322546, 'foreign')],\n",
      "  -1.4353397447852683),\n",
      " ([(0.014973372, 'govern'),\n",
      "   (0.010860678, 'parti'),\n",
      "   (0.0067026806, 'presid'),\n",
      "   (0.0064654127, 'leader'),\n",
      "   (0.0059845503, 'nation'),\n",
      "   (0.0058686086, 'u.s.'),\n",
      "   (0.005645592, 'state'),\n",
      "   (0.0055546695, 'unit'),\n",
      "   (0.0054533146, 'countri'),\n",
      "   (0.005341524, 'elect'),\n",
      "   (0.005036193, 'polit'),\n",
      "   (0.0049412954, 'militari'),\n",
      "   (0.0049384474, 'noriega'),\n",
      "   (0.004904055, 'offici'),\n",
      "   (0.0047776997, 'minist'),\n",
      "   (0.0047405595, 'peopl'),\n",
      "   (0.0046204836, 'communist'),\n",
      "   (0.0045110956, 'forc'),\n",
      "   (0.004492305, 'panama'),\n",
      "   (0.0039836764, 'unit_state')],\n",
      "  -1.530821640708427),\n",
      " ([(0.015882988, 'polic'),\n",
      "   (0.012178414, 'peopl'),\n",
      "   (0.010776022, 'kill'),\n",
      "   (0.007414976, 'citi'),\n",
      "   (0.007298566, 'two'),\n",
      "   (0.006707509, 'report'),\n",
      "   (0.006661773, 'fire'),\n",
      "   (0.005998558, 'one'),\n",
      "   (0.00586742, 'offici'),\n",
      "   (0.0051247245, 'mile'),\n",
      "   (0.0047501586, 'area'),\n",
      "   (0.0043243095, 'offic'),\n",
      "   (0.004281974, 'car'),\n",
      "   (0.004214229, 'armi'),\n",
      "   (0.004186509, 'three'),\n",
      "   (0.003937773, 'home'),\n",
      "   (0.0037780942, 'attack'),\n",
      "   (0.0036049432, 'bomb'),\n",
      "   (0.003550453, 'soldier'),\n",
      "   (0.0034734176, 'build')],\n",
      "  -1.6047554234713148),\n",
      " ([(0.010987523, 'air'),\n",
      "   (0.010462708, 'airlin'),\n",
      "   (0.010183371, 'flight'),\n",
      "   (0.009766871, 'plane'),\n",
      "   (0.007825002, 'u.s.'),\n",
      "   (0.006813707, 'ship'),\n",
      "   (0.006482124, 'pilot'),\n",
      "   (0.005986192, 'forc'),\n",
      "   (0.005820771, 'eastern'),\n",
      "   (0.005744598, 'navi'),\n",
      "   (0.005215288, 'offici'),\n",
      "   (0.004687517, 'airport'),\n",
      "   (0.00462371, 'crash'),\n",
      "   (0.0045963014, 'american'),\n",
      "   (0.004580088, 'aircraft'),\n",
      "   (0.004450121, 'oil'),\n",
      "   (0.004383821, 'two'),\n",
      "   (0.004249338, 'report'),\n",
      "   (0.0041197957, 'base'),\n",
      "   (0.0040635397, 'iran')],\n",
      "  -1.7289850655482695),\n",
      " ([(0.028290175, 'stock'),\n",
      "   (0.01913358, 'market'),\n",
      "   (0.014304742, 'trade'),\n",
      "   (0.010140394, 'share'),\n",
      "   (0.009756744, 'index'),\n",
      "   (0.009740232, 'bank'),\n",
      "   (0.009713855, 'palestinian'),\n",
      "   (0.009675327, 'exchang'),\n",
      "   (0.009367383, 'israel'),\n",
      "   (0.009147151, 'isra'),\n",
      "   (0.008636082, 'ceausescu'),\n",
      "   (0.008312822, 'point'),\n",
      "   (0.00694043, 'issu'),\n",
      "   (0.0066922405, 'bond'),\n",
      "   (0.0063047954, 'new'),\n",
      "   (0.005882921, 'wall'),\n",
      "   (0.005813843, 'investor'),\n",
      "   (0.0057847626, 'million'),\n",
      "   (0.005404264, 'industri'),\n",
      "   (0.005325862, 'close')],\n",
      "  -2.1274954349453155)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['150', 'former', 'offic', 'overthrown', 'south', 'vietnames', 'govern', 'releas', 're-educ', 'camp']\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"150 former offic overthrown south vietnames govern releas re-educ camp poep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['150',\n",
       " 'former',\n",
       " 'offic',\n",
       " 'overthrown',\n",
       " 'south',\n",
       " 'vietnam',\n",
       " 'govern',\n",
       " 'relea',\n",
       " 're-educ',\n",
       " 'camp',\n",
       " 'poep']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = read_ap.process_text(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1),\n",
       " (28, 1),\n",
       " (68, 1),\n",
       " (76, 1),\n",
       " (120, 1),\n",
       " (122, 1),\n",
       " (133, 1),\n",
       " (150, 1),\n",
       " (164, 1)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = model.id2word.doc2bow(query)\n",
    "# query\n",
    "query = dictionary.doc2bow(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"More than 150 former officers of the\n",
    "overthrown South Vietnamese government have been released from a\n",
    "re-education camp after 13 years of detention, the official Vietnam\n",
    "News Agency reported Saturday.\n",
    "The report from Hanoi, monitored in Bangkok, did not give\n",
    "specific figures, but said those freed Friday included an\n",
    "ex-Cabinet minister, a deputy minister, 10 generals, 115\n",
    "field-grade officers and 25 chaplains.\n",
    "   It quoted Col. Luu Van Ham, director of the Nam Ha camp south of\n",
    "Hanoi, as saying all 700 former South Vietnamese officials who had\n",
    "been held at the camp now have been released.\n",
    "   They were among 1,014 South Vietnamese who were to be released\n",
    "from re-education camps under an amnesty announced by the Communist\n",
    "government to mark Tet, the lunar new year that begins Feb. 17.\n",
    "   The Vietnam News Agency report said many foreign journalists and\n",
    "a delegation from the Australia-Vietnam Friendship Association\n",
    "attended the Nam Ha release ceremony.\n",
    "   It said Lt. Gen. Nguyen Vinh Nghi, former commander of South\n",
    "Vietnam's Third Army Corps, and Col. Tran Duc Minh, former director\n",
    "of the Army Infantry Officers School, expressed ``gratitude to the\n",
    "government for its humane treatment in spite of the fact that most\n",
    "of them (detainees) had committed heinous crimes against the\n",
    "country and people.''\n",
    "   The prisoners had been held without formal charges or trial\n",
    "since North Vietnam defeated the U.S.-backed South Vietnamese\n",
    "government in April 1975, ending the Vietnam War.\n",
    "   Communist authorities had called the prisoners war criminals and\n",
    "said they had to learn how to become citizens of the new society.\n",
    "   Small numbers had been released occasionally without publicity\n",
    "but the government announced last year that 480 political prisoners\n",
    "would be freed to mark National Day on Sept. 2.\n",
    "   On Thursday, Vice Minister of Information Phan Quang said 1,014\n",
    "would be released under the Tet amnesty.\n",
    "   He reported a total of 150 prisoners would remain in the camps,\n",
    "which he said once held 100,000.\n",
    "   ``Depending on their repentance, they will gradually be released\n",
    "within a short period of time,'' Quang said.\n",
    "   He said many of the former inmates would return to their\n",
    "families in Ho Chi Minh City, formerly the South Vietnamese capital\n",
    "of Saigon.\n",
    "   The amnesties apparently are part of efforts by Communist Party\n",
    "chief Nguyen Van Linh to heal internal divisions and improve\n",
    "Vietnam's image abroad.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = read_ap.process_text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 2),\n",
       " (13, 3),\n",
       " (14, 1),\n",
       " (15, 2),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (19, 2),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 5),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 2),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 3),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (54, 2),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (64, 1),\n",
       " (65, 1),\n",
       " (67, 1),\n",
       " (68, 5),\n",
       " (69, 1),\n",
       " (70, 2),\n",
       " (71, 1),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 1),\n",
       " (76, 5),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 2),\n",
       " (80, 1),\n",
       " (81, 2),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (85, 3),\n",
       " (86, 1),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (91, 1),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (100, 1),\n",
       " (101, 1),\n",
       " (102, 1),\n",
       " (104, 1),\n",
       " (105, 2),\n",
       " (106, 2),\n",
       " (107, 2),\n",
       " (109, 3),\n",
       " (110, 1),\n",
       " (112, 2),\n",
       " (113, 1),\n",
       " (114, 4),\n",
       " (115, 2),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 3),\n",
       " (121, 2),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 1),\n",
       " (126, 1),\n",
       " (127, 1),\n",
       " (129, 4),\n",
       " (130, 1),\n",
       " (131, 2),\n",
       " (132, 1),\n",
       " (133, 2),\n",
       " (135, 7),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 4),\n",
       " (139, 1),\n",
       " (140, 1),\n",
       " (141, 1),\n",
       " (142, 1),\n",
       " (143, 1),\n",
       " (144, 1),\n",
       " (145, 1),\n",
       " (147, 1),\n",
       " (148, 1),\n",
       " (149, 1),\n",
       " (150, 7),\n",
       " (151, 1),\n",
       " (153, 1),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 1),\n",
       " (157, 1),\n",
       " (158, 1),\n",
       " (159, 1),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 2),\n",
       " (163, 1),\n",
       " (164, 6),\n",
       " (166, 5),\n",
       " (167, 1),\n",
       " (168, 2),\n",
       " (169, 1),\n",
       " (170, 2)]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = dictionary.doc2bow(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.047774028), (2, 0.7972291), (4, 0.09066219), (6, 0.019111032), (8, 0.042699546)]\n"
     ]
    }
   ],
   "source": [
    "print(model[query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.047015667), (2, 0.80070025), (4, 0.0868585), (8, 0.06223184)]\n"
     ]
    }
   ],
   "source": [
    "print(model[corpus[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.04778037),\n",
       " (2, 0.79723895),\n",
       " (4, 0.09066447),\n",
       " (6, 0.019084737),\n",
       " (8, 0.042707335)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = model[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query = gensim.matutils.sparse2full(model[query], num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corp0 = gensim.matutils.sparse2full(model[corpus[0]], num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corp1 = gensim.matutils.sparse2full(model[corpus[1]], num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kullback_leibler(new_query, new_corp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.04702356, 0.80069256, 0.        , 0.08685537,\n",
       "       0.        , 0.        , 0.        , 0.06223481, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0365147 , 0.12522797, 0.0579267 , 0.09677395, 0.06265194,\n",
       "       0.03005568, 0.47769132, 0.02692753, 0.04017168, 0.04605851],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that ranks documents given a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_LDA(query, model, num_results = 10, num_topics = num_topics):\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        doc = gensim.matutils.sparse2full(model[corpus[i]], num_topics)\n",
    "        neg_kl = float(-1 * kullback_leibler(query, doc))\n",
    "        scores.append((i2str[i], neg_kl))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ranking_LDA(new_query, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = sorted(scores, key=lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
